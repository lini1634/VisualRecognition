
## AutoStiching

> 본 실습은 1주차 과제물입니다. 실습1,2를 마쳤을 경우 미리 실습하셔도 좋습니다.
- 본 문제의 가정: 해당 코드는 경로를 설정한 폴더에 있는 이미지 조각들을 자동으로 스티칭하고 있습니다.

# AutoStitching

#### 해당 실습은 앞선 [실습2](1주차-실습/Example_002.cpp)와 다르게 특정 폴더에 있는 이미지들을 순서에 상관없이 자동으로 이미지 스티칭을 진행하는 예제입니다. 앞 실습과 크게 다른점은 각 이미지들에 대한 특징점을 사전에 계산하고, 인라이너와 아웃라이너의 비율을 통해서 이미지 사이의 매칭 가능성을 계산한 후 이를 통해서 매칭 순서를 자동으로 설정, 이미지 스티칭을 진행합니다.

### 이미지 스티칭 자료 <br>
![default](https://user-images.githubusercontent.com/44772344/52432332-87109d80-2b4d-11e9-9820-33b882747a8c.PNG)

### 이미지 스티칭 과정 .gif  <br>
![ezgif com-video-to-gif](https://user-images.githubusercontent.com/44772344/52432205-38fb9a00-2b4d-11e9-935b-47eeedaf450d.gif)

### 이미지 스티칭 결과 <br>
![result](https://user-images.githubusercontent.com/44772344/52432277-66484800-2b4d-11e9-83e7-3148248986c1.jpg)

## 전체코드
[1주차-실습3.cpp](1주차-실습/Example_003.cpp)
## 부분 설명

#### 파노라마를 만드는 코드에 대해서는 [실습2](1주차-실습/Example_002.cpp)에서 다루고있습니다.<br>


```
	Image_feature Image_feature;


	String folderpath = "__이미지가 저장된 파일 경로";
	vector<String> filenames;
	glob(folderpath, filenames);

	cout << "\n------- file load ---------\n" << endl;

	for (size_t i = 0; i < filenames.size(); i++)
	{
		panorama.push_back(imread(filenames[i], IMREAD_COLOR));
		cout << filenames[i] << "  load" << endl;
	}
```

##### OPencv에서 제공하는 `glob` 함수를 통해서 지정해준 폴더(경로)에있는 filename 리스트를 읽어와 `imread` 를 진행하는데, 여기서 `imread`를 통해서 읽어온 이미지의 값은 `panorama`라는 `vectro<Mat>`형식에 `push_back`하는 형태로 대입합니다. 그렇게 되면 다음과 같은 모습으로 이미지의 값들이 저장되는 것을 확인할 수 있습니다. <br>
![vector](https://user-images.githubusercontent.com/44772344/52476735-ee2c6180-2be2-11e9-919a-73a955fe70f5.png)


```
typedef struct Image_feature 
{
	Mat descriptors;
	vector< KeyPoint > keypoint;
	Mat img;
}Image_feature;
```

##### 위의 코드는 이미지에 대한 descriptors,keypoint,img 를 쉽게 사용하기위해 `Image_feature`라는 구조체를 정의한 부분입니다. 


```
Image_feature find_image_fature(Mat img)
{
	vector< KeyPoint > keypoint;
	Image_feature img_class;
	Mat img_g;
	Mat descriptors;

	cvtColor(img, img_g, COLOR_BGR2GRAY);

	SiftDescriptorExtractor detector;
	detector.detect(img_g, keypoint);
	SiftDescriptorExtractor extractor;
	extractor.compute(img_g, keypoint, descriptors);

	img_class.descriptors = descriptors;
	img_class.keypoint = keypoint;
	img_class.img = img;

	return img_class;
}
```
##### 위의 코드는 입력받은 이미지에 대해서 SIFT 기법을 통해서 특징점을 찾는 코드입니다. 이는 [실습2](1주차-실습/Example_002.cpp) 에서 다루고 있습니다. 실습2와 다른점은 해당 함수의 타입은 앞서 만든 구조체 `Image_feature`로 `return` 값에는 descriptors,keypoint,img가 모두 들어있습니다.


```
   for (int i = 0; i < filenames.size() ; i++)
	{
		Image_feature = find_image_fature(panorama[i]);
		Image_array.push_back(Image_feature);
		cout <<  filenames[i] << " finish "<< endl;
	}
```
##### 위의 코드는 실제 main함수에서 `find_image_fature` 함수가 사용된 부분입니다. 이 함수를 통해서 구한 `Image_feature`를 `vector<Image_feature>`로 정의된 `Image_array`에 push_back하는 내용입니다. 이를 통해서 입력된 모든 이미지를 한 곳에 저장해 사용하기 쉽게 만들었습니다.


```
        vector<int> image_match_count;
	int match_count = 0;
	int bef_match_count = 0;
	int max_match = 0;
	int max_count = 0;
	for (int i = 0; i < filenames.size(); i++)
	{
		for (int j = 0; j < filenames.size(); j++)
		{
			if (i != j)
			{
				if ((find_matches_percent(Image_array[i], Image_array[j])) >= 10)	match_count++;
			}
		}
		if (max_count < match_count) {
			max_match = i;
			max_count = match_count;
		}
		cout << filenames[i] << " be matching " << match_count << " images" << endl;

		match_count = 0;

	}
	cout << "---" << max_match << endl;
```
##### 위의 코드는 autostiching을 하기 위해서 각 영상마다의 매칭가능성을 구하고 가장 많은 이미지와 매칭가능성이 높은 핵심 이미지를 찾아내는 과정입니다. 이를 통해서 이미지 스티칭을 진행할때 가장먼저 기준이될 이미지를 구하는 과정입니다. 아래 사진을 통해서 가장 많은 이미지와 매칭 가능성을 보인 이미지를 구합니다.<br>

![default](https://user-images.githubusercontent.com/44772344/52477481-62680480-2be5-11e9-8564-c9bf6aa052d1.png)<br>




```
   Image_array.erase(Image_array.begin() + max_match);
```


##### 이미지의 feature가 저장되있는 vector --Image_array변수에서 위에서 찾은 max_match를 없애줍니다.


```
Mat Panorama = imread(filenames[max_match], IMREAD_COLOR);
```
##### max_match인 영상을 기준점으로 초기화 시킵니다.

```
        double match = 0;
	int maxj = 0;
	double maxper = 0;
	for (int i = 0; i < filenames.size()-1; i++)
	{
		
		Image_feature = find_image_fature(Panorama);

		for (int j = 0; j < Image_array.size(); j++)
		{
		
			match = find_matches_percent(Image_feature, Image_array[j]);

			if (match>maxper)
			{
				maxper = match;
				maxj = j;
			}
		}
		cout << "--maxmatchdone--" <<maxj <<endl;
		Panorama = panorama_stiching(Image_feature, Image_array[maxj]);
		cout << maxj << endl;
		Image_array.erase(Image_array.begin() + maxj);
		cv::namedWindow("test", CV_WINDOW_FREERATIO);
		cv::imshow("test", Panorama);
		cv::waitKey(20);
		maxper = 0;
	}
```
##### 기준점과 가장 매칭도가 높은 영상을 찾아서 붙히고 붙혀진 영상을 다시 기준점으로 잡습니다.
```
   Image_feature = find_image_fature(Panorama);
```
##### 기준점의 feature을 찾아서 저장
```
                for (int j = 0; j < Image_array.size(); j++)
		{
		
			match = find_matches_percent(Image_feature, Image_array[j]);

			if (match>maxper)
			{
				maxper = match;
				maxj = j;
			}
		}
```
##### 기준점과 가장 매칭도가 높은 영상을 찾습니다.
```
Panorama = panorama_stiching(Image_feature, Image_array[maxj]);
```
##### 기준점을 stiching한 결과로 초기화

```
   double find_matches_percent(Image_feature img1, Image_feature img2)
```
##### img1과img2의 feature을 인자로 받아서 두 영상의 매칭 percent를 결과 값으로 return 해줍니다.

```
    Mat HomoMatrix = findHomography(img2_pt, img1_pt, RANSAC, 3, mask);
```
##### 이 코드까지는 실습 2에서 설명했으므로 생략 합니다. 다른점  findHomography함수에서 마지막에 인자로 mask를 넣어 주면 RANSAC 기법의 인라이너는 1 아웃라이너는 0으로 매칭점에 대한 인라이너 아웃라이너를 나타냅니다. 이를 이용해서 전체 매칭점(인라이너+아웃라이너) 중 인라이너의 비율을 구해서 두 사진의 매칭 가능성(확률)을 구하게 됩니다. 
```
    Mat panorama_stiching(Image_feature img1, Image_feature img2)
```
##### 사진 두개의 feature를 받아서 두개를 stiching 한 영상을 결과롤 return 해줍니다.<br>

```
        Mat matResult;
	Mat matPanorama;

	// 4개의 코너 구하기
	vector<Point2f> conerPt, conerPt_1;

	conerPt.push_back(Point2f(0, 0));
	conerPt.push_back(Point2f(img2.img.size().width, 0));
	conerPt.push_back(Point2f(0, img2.img.size().height));
	conerPt.push_back(Point2f(img2.img.size().width, img2.img.size().height));

	Mat P_Trans_conerPt;
	perspectiveTransform(Mat(conerPt), P_Trans_conerPt, HomoMatrix);

	// 이미지의 모서리 계산
	double min_x, min_y, max_x, max_y, bef_max_x;
	float min_x1, min_x2, min_y1, min_y2, max_x1, max_x2, max_y1, max_y2;

	min_x1 = min(P_Trans_conerPt.at<Point2f>(0).x, P_Trans_conerPt.at<Point2f>(1).x);
	min_x2 = min(P_Trans_conerPt.at<Point2f>(2).x, P_Trans_conerPt.at<Point2f>(3).x);
	min_y1 = min(P_Trans_conerPt.at<Point2f>(0).y, P_Trans_conerPt.at<Point2f>(1).y);
	min_y2 = min(P_Trans_conerPt.at<Point2f>(2).y, P_Trans_conerPt.at<Point2f>(3).y);
	max_x1 = max(P_Trans_conerPt.at<Point2f>(0).x, P_Trans_conerPt.at<Point2f>(1).x);
	max_x2 = max(P_Trans_conerPt.at<Point2f>(2).x, P_Trans_conerPt.at<Point2f>(3).x);
	max_y1 = max(P_Trans_conerPt.at<Point2f>(0).y, P_Trans_conerPt.at<Point2f>(1).y);
	max_y2 = max(P_Trans_conerPt.at<Point2f>(2).y, P_Trans_conerPt.at<Point2f>(3).y);
	min_x = min(min_x1, min_x2);
	min_y = min(min_y1, min_y2);
	max_x = max(max_x1, max_x2);
	max_y = max(max_y1, max_y2);

	// Transformation matrix
	Mat Htr = Mat::eye(3, 3, CV_64F);
	if (min_x < 0)
	{
		max_x = img1.img.size().width - min_x;
		Htr.at<double>(0, 2) = -min_x;
	}
	else
	{
		if (max_x < img1.img.size().width) max_x = img1.img.size().width;
	}

	if (min_y < 0)
	{
		max_y = img1.img.size().height - min_y;
		Htr.at<double>(1, 2) = -min_y;
	}
	else
	{
		if (max_y < img1.img.size().height) max_y = img1.img.size().height;
	}

	// 파노라마 만들기
	matPanorama = Mat(Size(max_x, max_y), CV_32F);
	warpPerspective(img1.img, matPanorama, Htr, matPanorama.size(), INTER_CUBIC, BORDER_CONSTANT, 0);
	warpPerspective(img2.img, matPanorama, (Htr*HomoMatrix), matPanorama.size(), INTER_CUBIC, BORDER_TRANSPARENT, 0);
```

##### 이 코드는 기준이 아닌 붙이고자 하는 이미지의 각 모서리를 구하고, 그 모서리에 해당하는 좌표만 perspectiveTransform 해서 이동했을때의 좌표를 구합니다. 이를 이용해 기준이되는 이미지와 이동했을때 이미지의 상관관계를 통해서 두개를 스티칭한 이미지가 갖는 최대의 크기를 계산합니다. 이를 통해 이미지 사이즈를 갖은 `matPanorama` 를 만들어 놓고 기준점이 되는 이미지와 붙일 이미지를 이동한 후 두개를 `warpPerspective`를 이용해 각 이미지(기준점이 되는 이미지와 새로 붙일 이미지)를 와핑합니다.이를 표현하면 다음과 같습니다. <br>


```
        vector<Point2f> conerPt, conerPt_1;

	conerPt.push_back(Point2f(0, 0));
	conerPt.push_back(Point2f(img2.img.size().width, 0));
	conerPt.push_back(Point2f(0, img2.img.size().height));
	conerPt.push_back(Point2f(img2.img.size().width, img2.img.size().height));
        //img2사이즈로 conerPt에 초기화
	Mat P_Trans_conerPt;
	perspectiveTransform(Mat(conerPt), P_Trans_conerPt, HomoMatrix);
```

##### 붙이려는 이미지의 각 모서리의 좌표를 구하는 코드입니다. 모서리를 구한다음 각 좌표를 앞에서 구한 `HomoMatrix`를 `perspectiveTransform` 함수를 이용해 이미지 와핑 시킵니다. 

```
        double min_x, min_y, max_x, max_y, bef_max_x;
	float min_x1, min_x2, min_y1, min_y2, max_x1, max_x2, max_y1, max_y2;

	min_x1 = min(P_Trans_conerPt.at<Point2f>(0).x, P_Trans_conerPt.at<Point2f>(1).x);
	min_x2 = min(P_Trans_conerPt.at<Point2f>(2).x, P_Trans_conerPt.at<Point2f>(3).x);
	min_y1 = min(P_Trans_conerPt.at<Point2f>(0).y, P_Trans_conerPt.at<Point2f>(1).y);
	min_y2 = min(P_Trans_conerPt.at<Point2f>(2).y, P_Trans_conerPt.at<Point2f>(3).y);
	max_x1 = max(P_Trans_conerPt.at<Point2f>(0).x, P_Trans_conerPt.at<Point2f>(1).x);
	max_x2 = max(P_Trans_conerPt.at<Point2f>(2).x, P_Trans_conerPt.at<Point2f>(3).x);
	max_y1 = max(P_Trans_conerPt.at<Point2f>(0).y, P_Trans_conerPt.at<Point2f>(1).y);
	max_y2 = max(P_Trans_conerPt.at<Point2f>(2).y, P_Trans_conerPt.at<Point2f>(3).y);
	min_x = min(min_x1, min_x2);
	min_y = min(min_y1, min_y2);
	max_x = max(max_x1, max_x2);
	max_y = max(max_y1, max_y2);
```
##### `HomoMatrix`로 변환한 이미지의 각 좌표를 통해서 이미지가 와핑됐을 때, 이미지의 크기를 구하기 위해서 X와 Y값의 Min,Max를 구합니다. 이는 위에서 나타낸 다음 과정을 진행할때 panorama의 크기를 구하기 위한 과정입니다. 



 ```
        Mat Htr = Mat::eye(3, 3, CV_64F);
	if (min_x < 0)
	{
		max_x = img1.img.size().width - min_x;
		Htr.at<double>(0, 2) = -min_x;
	}
	else
	{
		if (max_x < img1.img.size().width) max_x = img1.img.size().width;
	}

	if (min_y < 0)
	{
		max_y = img1.img.size().height - min_y;
		Htr.at<double>(1, 2) = -min_y;
	}
	else
	{
		if (max_y < img1.img.size().height) max_y = img1.img.size().height;
	}
 ```
 
##### 위의 과정을 통해서 panorama의 size를 정했으면 앞서 실습2에서 진행한 방법과 같이 warp를 합니다. 다만 여기서 기본적으로 각 이미지를 전체 크기에 맞춰서 쉬프트해서 이미지를 warp 합니다. 좀 더 쉬운 설명으로는 다음과 같습니다. 


![panorama_image](https://user-images.githubusercontent.com/44772344/52470530-ba950b80-2bd1-11e9-8557-fafc86df559f.gif)

![ezgif com-gif-maker](https://user-images.githubusercontent.com/44772344/52481807-ea084000-2bf2-11e9-883c-e6a76c95737a.gif)


