# MNIST 데이터셋을 통한 SVM 학습


## 본 파일 실행을 위해 data1의 MNIST.zip의 압축을 풀어야하며,  [CNN_train_rs.csv](http://bigfile.mail.naver.com/bigfileupload/download?fid=g9FRWrFjWXKqFqKjK3e0KxUXFwYZKAulKAUwFoUwKov9KIYwFxEZaxUwKxvlHqKXK4pSKxblFoUlaxUlKrMwKxK9MoK9MxblMotlFxvr) 를 받으셔야합니다. 해당파일은 모두 data1 폴더에 첨부해주시길 바랍니다.

<br> 

## MNIST 데이터 HOG(Histogram of Gradient)로 특징량 검출

### HOG : [참고가 될 설명](https://donghwa-kim.github.io/hog.html)


### Input Iamge Information : 20x20의 MNIST Image 5000장 (각 클래스(0~9) 별 500장)

#### 가장먼저 HOG Descriptor를 추출할 이미지를 OPenCV의 `imread`를 이용해 불러옵니다. 이번 실습에서 제공하는 MNIST Image의 이름 정의에 대해서 'data 4_122'를 예로들어 간단히 설명하자면,'data 4_122'라는 이름을 갖는 이미지는 4를 나타내는 손글씨 사진 중 122번째를 의미합니다. 0~9까지의 숫자를 손글씨로 작성하였고 각 클래스별로 총 500장이 있습니다.

```C++
		cout << "\n//////////////////////////////////////////////////////" << endl;

	cout << "train Image load" << endl;

	for(int num=0; num<10; num++)
	{
		cout << num << " image load" << endl;
		for (int i = 0; i < NUMBER_train; i++)
		{
			Mat MNIST = imread("./MNIST/data "+ std::to_string(num) + "_" +std::to_string(i + 1) + ".PNG",COLOR_RGB2GRAY);
			if (!(MNIST.data))
			{
				cout << "image load fail" << endl;
				return 0;
			}
			HOG_train_data.push_back(find_HOG_feature_image(MNIST));
			HOG_train_data_label.push_back(num);
		}

	}
	cout << "\n//////////////////////////////////////////////////////" << endl;
	

```

#### 다음으로는 OPencv에서 제공하는 HOGDescriptor class를 통해서 HOGDescriptor를 계산해야합니다. 이 과정을 진행하는 함수는 다음과 같습니다.

![hog gif](https://user-images.githubusercontent.com/44772344/52908418-fe1a0480-32b8-11e9-8359-f5e2bfc0993e.gif)

```C++
vector<float> find_HOG_feature_image(Mat img)
{
	HOGDescriptor IMAGE_HOG
	(
		Size(20, 20), //winSize
		Size(8, 8), //blocksize
		Size(4, 4), //blockStride,
		Size(8, 8), //cellSize,
		9, //nbins,
    /////////////// 밑에 파라미터는 추가적으로 공부하시길 바랍니다.
		1, //derivAper,
		-1, //winSigma,
		0, //histogramNormType,
		0.2, //L2HysThresh,
		0,//gammal correction,
		64//nlevels=64
	);

	vector<float> hog_descriptor;
	IMAGE_HOG.compute(img, hog_descriptor);
	return hog_descriptor;

}
```
![ezgif com-gif-maker](https://user-images.githubusercontent.com/44772344/52755939-0c5eeb00-3043-11e9-9e1c-c9a236566788.gif) <br>

#### HOGDescriptor를 사용하기위해 `HOGDescriptor IMAGE_HOG` 와 같이 설정합니다. 다만 이 과정에서 자신이 입력할 이미지에 따라 Block size, Block Stride, cell size를 설정해주고 총 몇개의 회전방향을 구분할지 nbins를 설정해주면 됩니다. 이후의 변수들은 일반적으로는 디폴트 값을 설정합니다. 이 과정을 통해서 입력한 MNIST 이미지 5000장에 대한 `HOG Decriptor`를 추출해 저장합니다. 이 때  `HOG Decriptor`는 `vector<vector<float>>`의 형태로 저장되고 있습니다. 이후에는 SVM(Support Vector Machine)을 통해서 분류를 진행할 예정인데, OPENCV에서 주어지는 SVM함수는 다음과 같이 Mat 형태를 argument로 요구하고 있습니다. 따라서 `ConvertVectortoMatrix` 함수를 통해서 `vector<vector<float>>`형태로 저장한 `HOG Decriptor`를 Mat 형태로 변환해줍니다. 

```C++
	int descriptor_size = HOG_train_data[0].size();

	Mat HOG_train_data_Mat(HOG_train_data.size(), descriptor_size, CV_32FC1);
	Mat HOG_test_data_Mat(HOG_test_data.size(), descriptor_size, CV_32FC1);
	Mat HOG_train_data_label_Mat(HOG_train_data_label.size(), 1, CV_32FC1);
	Mat HOG_test_data_label_Mat(HOG_test_data_label.size(), 1, CV_32FC1);

	ConvertVectortoMatrix(HOG_train_data, HOG_test_data, HOG_train_data_Mat, HOG_test_data_Mat);

	for (int i = 0; i < HOG_train_data_label.size(); i++)
	{
		HOG_train_data_label_Mat.at<float>(i, 0) = HOG_train_data_label[i];
	}
	for (int i = 0; i < HOG_test_data_label.size(); i++)
	{
		HOG_test_data_label_Mat.at<float>(i, 0) = HOG_test_data_label[i];
	}
	
	
	..(생략)..
	
	
	void ConvertVectortoMatrix(vector<vector<float> > &trainHOG, vector<vector<float> > &testHOG, Mat &trainMat, Mat &testMat)
{

	int descriptor_size = trainHOG[0].size();

	for (int i = 0; i < trainHOG.size(); i++)
	{
		for (int j = 0; j < descriptor_size; j++) 
		{
			trainMat.at<float>(i, j) = trainHOG[i][j];
		}
	}
	for (int i = 0; i < testHOG.size(); i++)
	{
		for (int j = 0; j < descriptor_size; j++)
		{
			testMat.at<float>(i, j) = testHOG[i][j];
		}
	}
}

```
#### 다음과 같이 vector에서 Mat 형태로 변환했다면 이제 SVM을 이용해서 분류를 진행합니다. SVM을 이용하기 위해서는 직접 파라미터를 수정할 수도 있고 `train_auto`를 통해서 자동으로 구할 수 있습니다. 이 예제에서는 자동으로 구했으며, `train_auto`실행할 경우 오랜 시간이 소모됩니다. 따라서 미리 실행해서 구한 svm 파일을 올려놨으니 [MNIST_HOG_SVM_Linear_acc97.xml](https://github.com/moduPlayGround/ComputerVision-for-VisualRecognition/blob/master/2%EC%A3%BC%EC%B0%A8-%EC%8B%A4%EC%8A%B5/data2/MNIST_HOG_SVM_Linear_acc97.xml) 이 부분을 건너뛰고 싶으시다면, [예제1_2](https://github.com/moduPlayGround/ComputerVision-for-VisualRecognition/blob/master/2%EC%A3%BC%EC%B0%A8-%EC%8B%A4%EC%8A%B5/Example_002_1_2.cpp)로 넘어가시면 됩니다.

```C++

	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm setting                      " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;

	CvSVM svm;

	CvSVMParams params = CvSVMParams
    (
	  CvSVM::C_SVC,   // Type of SVM, here N classes (see manual)
	  CvSVM::LINEAR,  // kernel type (see manual)
	  0.0,            // kernel parameter (degree) for poly kernel only
	  0.0,            // kernel parameter (gamma) for poly/rbf kernel only
	  0.0,            // kernel parameter (coef0) for poly/sigmoid kernel only
	  10,             // SVM optimization parameter C
	  0,              // SVM optimization parameter nu (not used for N classe SVM)
	  0,              // SVM optimization parameter p (not used for N classe SVM)
	  NULL,           // class wieghts (or priors)
	  // Optional weights, assigned to particular classes.
	  // They are multiplied by C and thus affect the misclassification
	  // penalty for different classes. The larger weight, the larger penalty
	  // on misclassification of data from the corresponding class.

	  // termination criteria for learning algorithm

	  cvTermCriteria(CV_TERMCRIT_ITER + CV_TERMCRIT_EPS, 1000, 0.000001)

   );

	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm train                      " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;

	svm.train_auto(HOG_train_data_Mat, HOG_train_data_label_Mat, Mat(), Mat(), params, 10);

	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm save                   " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;

	svm.save("MNIST_HOG_SVM.xml");


```

#### 해당 과정에 대해서 설명하자면, 해당 입력으로 들어가는 파라미터에 대한 값은 실험적으로 가장 높은 정확도를 보이는 파라미터를 구해야합니다. 이를 OPENCV에서는 `train_auto`를 통해서 자동으로 구하게 해줍니다. 다만 값을 변화시키며 구하기 때문에 시간소모가 엄청난 편입니다. 미리 실행해서 구한 파라미터는 `params.gamma = 0.50625`와 rbf를 진행할 경우 `params.C = 2.5`가 나옵니다. 이러한 파라미터를 갖는 SVM을 생성한 후 학습을 위해서 데이터를 입력합니다. SVM을 학습하기위해서는 (OPencv2.4버전기준) 위에서  구한`HOG Decriptor`를 포함하는 Mat 과 각 `HOG Decriptor`가 가르키는 Label 값을 정리한 Mat을 입력해줘야 합니다. 좀 더 쉽게 설명하자면 다음과 같습니다. 

![svm_input](https://user-images.githubusercontent.com/44772344/52757499-2f3fce00-3048-11e9-8af6-a5f6d723ea6a.png)

#### 다음과 같은 데이터를 `svm.train`에 입력하면 분류기는 자동으로 입력된 데이터들을 라벨에 따라서 구분짓고 이후에 데이터가 들어왔을때 들어온 데이터가 어떠한 영역에 해당되는지에 대한 예측을 진행할 수 있습니다. 

#### 학습을 마쳤다면 이제 예측을 진행해보겠습니다. 위에서 train 이미지를 불러온 방법과 마찬가지로 이전에 불러온적 없는 test 이미지를 불러오고 각 이미지에 대한 descriptor를 구합니다. 그리고 이 구한 descriptor를 svm에 넣어서 어떠한 결과가 나오는지 정확도를 구합니다. 이때 정확도는 test 데이터에 대한 라벨 정보를 갖고 있기 때문에 Svm으로 분류된 값이랑 기존 label 값이랑 비교해 구할 수 있습니다. 해당 파트에 대한 부분은 다음에서 확인할 수 있습니다.

```C++
svm.predict(MNIST_test_HOG_Mat, testResponse);

	float count = 0, accuracy = 0;
	for (int i = 0; i < testResponse.rows; i++)
	{
		if (testResponse.at<float>(i, 0) == MNIST_test_label[i])
		{
			count = count + 1;
		}
	}

	accuracy = (count / testResponse.rows) * 100;


	cout << "accuracy : " << accuracy << endl;
```

#### 해당 과정을 통한 이번 이미지에 대한 정확도는 약 97%가 나오는것을 확인할 수 있습니다. 추가적으로 매번 train 이미지의 descriptor를 구하고 svm을 train하는 과정은 이번 실습에서는 5000장이였지만, 이미지가 많아지면 많은 시간이 소모됩니다. 따라서 학습한 svm을 다음과 같이 저장해서 다음에는 바로 svm.predict을 진행할 수 있습니다.

```C++
	
	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm predict                      " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;
	
	Mat Response_test;
	Mat Response_train;
	
	svm.predict(HOG_train_data_Mat, Response_train);
	float count_train = 0, accuracy_train = 0;
	for (int i = 0; i < Response_train.rows; i++)
	{
		if (Response_train.at<float>(i, 0) == HOG_train_data_label[i])
		{
			count_train = count_train + 1;
		}
	}

	svm.predict(HOG_test_data_Mat, Response_test);
	float count_test = 0, accuracy_test = 0;
	for (int i = 0; i < Response_test.rows; i++)
	{
		if (Response_test.at<float>(i, 0) == HOG_test_data_label[i])
		{
			count_test = count_test + 1;
		}
	}

	accuracy_train = (count_train / Response_train.rows) * 100;
	cout << "accuracy_train : " << accuracy_train << endl;
	accuracy_test = (count_test / Response_test.rows) * 100;
	cout << "accuracy_test : " << accuracy_test << endl;
	
```
####  이 예제에서는 약 97%의 정확도를 보이고 있습니다. 이를 전반적으로 이해하셨다면, 'Example_002_1_2.cpp'도 무리없이 진행하실 수 있으니, 생략하겠습니다. 'Example_002_1_2.cpp'와 관련해 질문은 이슈에 남겨주세요 .. 



## MNIST 데이터 CNN(convolutional neural network)으로 특징량 검출

### 해당 예제에서는 이미 학습된 VGG16 모델을 사용해 CNN 특징량을 검출하고 이 데이터를 C++로 가져와 SVM을 진행하였습니다. 
### 또한 Google에서 제공하는 colab을 사용하여 CNN 특징량을 검출하였습니다. [colab이란?](https://colab.research.google.com/notebooks/gpu.ipynb)

#### 가장먼저 GPU를 무료로 사용할 수 있는 Colab과 파이썬으로 작성된 오픈 소스 신경망 라이브러리인 케라스, 케라스를 포함하고 있는 다양한 작업에대해 데이터 흐름 프로그래밍을 위한 오픈소스 소프트웨어 라이브러리 텐서플로우를 이용해 CNN의 feature를 검출합니다. Coalb에서는 이 모든 라이브러리가 이미 설치돼 있습니다. 해당 방법은 아래 주소에서 확인하실 수 있습니다. 해당 코드는 구글드라이브에 특징량을 추출한 이미지들을 모두 업로드 한 후 colab에서 구글 드라이브와 연동해 해당 파일을 불러오고 케라스를 통해서 이미 학습된 VGG16모델을 통해서 각 이미지에 대한 특징량을 추출한 코드입니다. 더 관심있으신 분은 말씀해주시면 설명해드리겠습니다. (해당 메뉴얼에서는 colab에 대해서 자세히 다루지 않겠습니다.)
[VGG16_MNIST_train_final.ipynb](https://colab.research.google.com/github/socome/Computer-Vision-Study/blob/master/VGG16_MNIST_train_final.ipynb)
[VGG16_MNIST_test_final.ipynb](https://colab.research.google.com/github/socome/Computer-Vision-Study/blob/master/VGG16_MNIST_test_final.ipynb)

#### 위의 과정을 통해서 추출된 특징량에 대한 정보는 1장의 이미지당 (1,4096) 벡터로 나오게 됩니다. 이에 대한 설명은 다음 그림에서 알 수 있습니다. 

![1](https://user-images.githubusercontent.com/44772344/52900064-d41efe80-3234-11e9-879c-b02f2c5d30c8.png)

#### 다음 그림과 같이 최종 (1x1x4096)의 특징량을 (1,4096)으로 리사이즈해서 총 4500장에 대한 특징량 (45600x4096)의 크기를 갖는 이미지를 .csv 파일로 저장했습니다. 이 csv파일은 './data2'에서 받을 수 있습니다. 그럼 이렇게 Colab을 통해서 구한 CNN feature를 가지고 앞서 HOG feature에서 진행한 것과 마찬가지로 SVM 학습을 진행하겠습니다. 가장먼저 .csv를 읽는 코드입니다.


```C++
	vector<vector<float>> CNN_train_data_label = CsvtoVector("./image_train_label_rs.csv");
	vector<vector<float>> CNN_train_data = CsvtoVector("./image_train_rs.csv");
	vector<vector<float>> CNN_test_data_label = CsvtoVector("./image_test_label_rs.csv");
	vector<vector<float>> CNN_test_data = CsvtoVector("./image_test_rs.csv");
	
	..(생략)...
	
	vector<vector<float>> CsvtoVector(String filename)
{
	ifstream train_data(filename);
	vector<vector<float> > vector_data;

	if (!train_data.is_open())
	{
		cout << "Error: File Opne" << endl;
	}
	else
	{
		cout << "Find : " << filename << endl;
		cout << "starting loading" << endl;
	}

	if (train_data)
	{
		int cnt = 0;
		string line;
		while (getline(train_data, line))
		{
			vector<float> train_data_vector_2;
			stringstream linStream(line);
			string cell;
			cnt++;
			while (getline(linStream, cell, ','))
			{
				train_data_vector_2.push_back(stof(cell));
			}
			
			vector_data.push_back(train_data_vector_2);
		}
	}
	cout << "finished loading " << endl<<endl;

	return vector_data;
}

```

#### 해당 코드에 대해서 간략히 설명하자면, `fstream`클래스를 통해서 `.csv`파일을 불러오는 방법입니다. `getline`함수를 통해서 한 줄(여기서는 (1,4096) 벡터가 됩니다.)을 읽어오고 `,`를 구분자로 데이터를 하나씩 push_back하고 있습니다. 이후에 한 줄(하나의 이미지에 대한 CNN feature)를 다 읽었다면, 한 차원 위의 벡터에 그 값을 저장하고 다시 또 다음 이미지에서 추출한 CNN feature를 읽기 시작합니다. 이와 같은 방법으로 각 이미지의 대한 특징량은 `vector<float>`의 형태로 읽어오고 그 보다 한 차원 위인 `vector<vector<float>>`에 저장해나가면서 최종적으로는 (4500,4096)의 벡터를 만들게 됩니다. 이후에는 앞에서 이야기한것 같이 HOG feature에서 진행한 것과 마찬가지로 SVM(Support Vector Machine)을 통해서 분류를 진행하기 위해서 `ConvertVectortoMatrix` 함수를 통해서 `vector<vector<float>>`형태로 저장한 `CNN Decriptor`를 Mat 형태로 변환해줍니다. 그리고 이후 과정은 HOG때와 마찬가지로 SVM을 학습하는 과정이기 때문에 HOG와 동일한 방법으로 코드를 작성합니다.

```C++
	ConvertVectortoMatrix(CNN_train_data, MNIST_CNN_train_data_Mat);
	ConvertVectortoMatrix(CNN_test_data, MNIST_CNN_test_data_Mat);

	for (int i = 0; i < CNN_train_data_label.size(); i++)
	{
		MNIST_CNN_train_data_label_Mat.at<float>(i, 0) = CNN_train_data_label[i][0];
	}
	for (int i = 0; i < CNN_test_data_label.size(); i++)
	{
		MNIST_CNN_test_data_label_Mat.at<float>(i, 0) = CNN_test_data_label[i][0];
	}


	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm setting                      " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;

	CvSVM svm;
	
	 CvSVMParams params = CvSVMParams
	 (
	  CvSVM::C_SVC,   // Type of SVM, here N classes (see manual)
	  CvSVM::LINEAR,  // kernel type (see manual)
	  0.0,            // kernel parameter (degree) for poly kernel only
	  0.0,            // kernel parameter (gamma) for poly/rbf kernel only
	  0.0,            // kernel parameter (coef0) for poly/sigmoid kernel only
	  10,             // SVM optimization parameter C
	  0,              // SVM optimization parameter nu (not used for N classe SVM)
	  0,              // SVM optimization parameter p (not used for N classe SVM)
	  NULL,           // class wieghts (or priors)
	  // Optional weights, assigned to particular classes.
	  // They are multiplied by C and thus affect the misclassification
	  // penalty for different classes. The larger weight, the larger penalty
	  // on misclassification of data from the corresponding class.

	  // termination criteria for learning algorithm

	  cvTermCriteria(CV_TERMCRIT_ITER + CV_TERMCRIT_EPS, 1000, 0.000001)
    );

	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm train                      " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;
	
	svm.train_auto(MNIST_CNN_train_data_Mat, MNIST_CNN_train_data_label_Mat, Mat(), Mat(), params, 10);

	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm predict                      " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;

	Mat Response_test;
	Mat Response_train;


	svm.predict(MNIST_CNN_test_data_Mat, Response_test);
	float count_test = 0, accuracy_test = 0;

	for (int i = 0; i < Response_test.rows; i++)
	{
		if (Response_test.at<float>(i, 0) == CNN_test_data_label[i][0])
		{
			count_test = count_test + 1;
		}
	}

	svm.predict(MNIST_CNN_train_data_Mat, Response_train);
	float count_train = 0, accuracy_train = 0;

	for (int i = 0; i < Response_train.rows; i++)
	{
		if (Response_train.at<float>(i, 0) == CNN_train_data_label[i][0])
		{
			count_train = count_train + 1;
		}
	}

	accuracy_test = (count_test / Response_test.rows) * 100;
	cout << "accuracy_test : " << accuracy_test << endl;
	accuracy_train = (count_train / Response_train.rows) * 100;
	cout << "accuracy_train : " << accuracy_train << endl;


	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm save                   " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;
	/// Save svm file
	svm.save("MNIST_CNN_SVM.xml");
```


#### 이렇게 되면 정확도는 약 94%가 나오는 것을 확인하실 수 있습니다.
